{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "using BSON: @load\n",
    "using Flux\n",
    "using Flux: chunk\n",
    "using Flux.Data: DataLoader\n",
    "using ImageFiltering\n",
    "using Images\n",
    "using ImageIO\n",
    "using MLDatasets: FashionMNIST\n",
    "using LinearAlgebra\n",
    "using MLDatasets\n",
    "using Plots\n",
    "using Zygote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PLUGIn_CS (generic function with 1 method)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function PLUGIn_CS(G, y, A, max_iter, stepsize, tolerance, out_toggle)\n",
    "    \n",
    "    (_, z_dim) = size(Flux.params(G[1])[1]);\n",
    "    W = I(z_dim)\n",
    "  \n",
    "    #normalize the weights of the network\n",
    "    for i in 1:length(G)\n",
    "        _, s, _ = svd(Flux.params(G[i])[1])\n",
    "        W = Flux.params(G[i])[1] * W /s[1]\n",
    "    end\n",
    "  \n",
    "    z = randn(z_dim)\n",
    "    iter = 1\n",
    "    succ_error = 1\n",
    "  \n",
    "    while iter <= max_iter && succ_error > tolerance\n",
    "      \n",
    "      # d gives the PLUGIn direction\n",
    "      d = W'*A'*(A * G(z) - y)\n",
    "      z -= stepsize * d\n",
    "      succ_error = norm(stepsize * d)\n",
    "      if iter % out_toggle == 0  \n",
    "          println(\"====> In quasi-gradient: Iteration: $iter Successive error: $succ_error\")\n",
    "      end\n",
    "      iter += 1\n",
    "    end\n",
    "    println(\"====> In quasi-gradient: Iteration: $iter Successive error: $succ_error\")\n",
    "  \n",
    "    return z\n",
    "  end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GD_CS (generic function with 1 method)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function GD_CS(G, y, A, max_iter, stepsize, tolerance, out_toggle)\n",
    "\n",
    "    z = randn(20)\n",
    "    iter = 1\n",
    "    succ_error = 1\n",
    "    while iter <= max_iter && succ_error > tolerance\n",
    "        # d gives the PLUGIn direction\n",
    "        d = gradient(z -> norm(y - A*G(z)), z)[1]\n",
    "        z -= stepsize * d\n",
    "        succ_error = norm(stepsize * d)\n",
    "        if iter % out_toggle == 0  \n",
    "            println(\"====> In quasi-gradient: Iteration: $iter Successive error: $succ_error\")\n",
    "        end\n",
    "        iter += 1\n",
    "    end\n",
    "    println(\"====> In quasi-gradient: Iteration: $iter Successive error: $succ_error\")\n",
    "\n",
    "    return z\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> In quasi-gradient: Iteration: 1000 Successive error: 1.1941512463987172e-6\n",
      "====> In quasi-gradient: Iteration: 2000 Successive error: 3.1535913288548917e-10\n",
      "====> In quasi-gradient: Iteration: 3000 Successive error: 7.572969627436639e-14\n",
      "====> In quasi-gradient: Iteration: 3270 Successive error: 9.963993939425636e-15\n",
      "recovery error: 7.194882961768809e-13, reconstruction error: 2.0801248898565373e-13\n"
     ]
    }
   ],
   "source": [
    "#setup a synthetic problem\n",
    "G = Chain(\n",
    "    Dense(20, 500, relu, bias = false; initW =(out,in) ->  randn(500, 20)/sqrt(500)),\n",
    "    Dense(500, 500, relu, bias = false; initW =(out,in) -> randn(500, 500)/sqrt(500)),\n",
    "    Dense(500, 784, relu, bias = false; initW =(out,in) -> randn(784, 500)/sqrt(784))\n",
    ")\n",
    "\n",
    "\n",
    "z = randn(20)\n",
    "m = 300; A = randn(m, 784)/sqrt(m)\n",
    "y = A*G(z) + 1e-14 * randn(m)\n",
    "\n",
    "stepsize = 2\n",
    "tolerance = 1e-14\n",
    "max_iter = 10000\n",
    "out_toggle = 1000\n",
    "z_rec = PLUGIn_CS(G,y,A, max_iter, stepsize, tolerance, out_toggle)\n",
    "recov_error = norm(z - z_rec)\n",
    "recon_error = norm(G(z) - G(z_rec))\n",
    "println(\"recovery error: $recov_error, reconstruction error: $recon_error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "load_model (generic function with 1 method)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# experiments with MNIST dataset\n",
    "function load_model(load_dir::String, epoch::Int)\n",
    "    print(\"Loading model...\")\n",
    "    @load joinpath(load_dir, \"model-$epoch.bson\") encoder_μ encoder_logvar decoder\n",
    "    println(\"Done\")\n",
    "    return encoder_μ, encoder_logvar, decoder\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "get_train_loader (generic function with 1 method)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function get_train_loader(batch_size, shuffle::Bool)\n",
    "    # The MNIST training set is made up of 60k 28 by 28 greyscale images\n",
    "    train_x, train_y = MNIST.traindata(Float32)\n",
    "    train_x = 1 .- reshape(train_x, (784, :))\n",
    "    return DataLoader((train_x, train_y), batchsize=batch_size, shuffle=shuffle, partial=false)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model...Done\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(Chain(Chain(Dense(784, 500, relu), Dense(500, 500, relu)), Dense(500, 20)), Chain(Chain(Dense(784, 500, relu), Dense(500, 500, relu)), Dense(500, 20)), Chain(Dense(20, 500, relu; bias=false), Dense(500, 500, relu; bias=false), Dense(500, 784, σ; bias=false)))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epoch_to_load = 20\n",
    "# Load the model and test set loader\n",
    "#encoder_mu, encoder_logvar, decoder = load_model(\"result\", epoch_to_load)\n",
    "encoder_mu, encoder_logvar, decoder = load_model(\"result/MNIST\", epoch_to_load)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "stdin>  y\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This program has requested access to the data dependency MNIST.\n",
      "which is not currently installed. It can be installed automatically, and you will not see this message again.\n",
      "\n",
      "Dataset: THE MNIST DATABASE of handwritten digits\n",
      "Authors: Yann LeCun, Corinna Cortes, Christopher J.C. Burges\n",
      "Website: http://yann.lecun.com/exdb/mnist/\n",
      "\n",
      "[LeCun et al., 1998a]\n",
      "    Y. LeCun, L. Bottou, Y. Bengio, and P. Haffner.\n",
      "    \"Gradient-based learning applied to document recognition.\"\n",
      "    Proceedings of the IEEE, 86(11):2278-2324, November 1998\n",
      "\n",
      "The files are available for download at the offical\n",
      "website linked above. Note that using the data\n",
      "responsibly and respecting copyright remains your\n",
      "responsibility. The authors of MNIST aren't really\n",
      "explicit about any terms of use, so please read the\n",
      "website to make sure you want to download the\n",
      "dataset.\n",
      "\n",
      "\n",
      "\n",
      "Do you want to download the dataset from [\"https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\", \"https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\", \"https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\", \"https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\"] to \"/opt/julia/datadeps/MNIST\"?\n",
      "[y/n]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataLoader{Tuple{Matrix{Float32}, Vector{Int64}}, Random._GLOBAL_RNG}((Float32[1.0 1.0 … 1.0 1.0; 1.0 1.0 … 1.0 1.0; … ; 1.0 1.0 … 1.0 1.0; 1.0 1.0 … 1.0 1.0], [5, 0, 4, 1, 9, 2, 1, 3, 1, 4  …  9, 2, 9, 5, 1, 8, 3, 5, 6, 8]), 64, 60000, false, 59937, [1, 2, 3, 4, 5, 6, 7, 8, 9, 10  …  59991, 59992, 59993, 59994, 59995, 59996, 59997, 59998, 59999, 60000], true, Random._GLOBAL_RNG())"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pick a image in MNIST to denoise\n",
    "num = 8\n",
    "batch_size = 64\n",
    "shuffle_data = true\n",
    "dataloader = get_train_loader(batch_size, shuffle_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> In quasi-gradient: Iteration: 1000 Successive error: 0.053126221360445224\n",
      "====> In quasi-gradient: Iteration: 2000 Successive error: 0.05623084468364893\n",
      "====> In quasi-gradient: Iteration: 3000 Successive error: 0.05459704474526513\n",
      "====> In quasi-gradient: Iteration: 4000 Successive error: 0.055005210686865535\n",
      "====> In quasi-gradient: Iteration: 5000 Successive error: 0.05638883476486583\n",
      "====> In quasi-gradient: Iteration: 6000 Successive error: 0.056799390446632396\n",
      "====> In quasi-gradient: Iteration: 7000 Successive error: 0.05704838245217213\n",
      "====> In quasi-gradient: Iteration: 8000 Successive error: 0.0572244139312179\n",
      "====> In quasi-gradient: Iteration: 9000 Successive error: 0.05735688982888102\n",
      "====> In quasi-gradient: Iteration: 10000 Successive error: 0.057462034333574497\n",
      "====> In quasi-gradient: Iteration: 10001 Successive error: 0.057462034333574497\n",
      "reconstruction error: 6.0879239926856465\n",
      "====> In quasi-gradient: Iteration: 1000 Successive error: 0.9167083536621017\n",
      "====> In quasi-gradient: Iteration: 2000 Successive error: 0.908685228312983\n",
      "====> In quasi-gradient: Iteration: 3000 Successive error: 0.942086946047468\n",
      "====> In quasi-gradient: Iteration: 4000 Successive error: 0.9459596684925403\n",
      "====> In quasi-gradient: Iteration: 5000 Successive error: 0.8680346210104379\n",
      "====> In quasi-gradient: Iteration: 6000 Successive error: 0.928941858274877\n",
      "====> In quasi-gradient: Iteration: 7000 Successive error: 0.9727254994071023\n",
      "====> In quasi-gradient: Iteration: 8000 Successive error: 0.8354492290798594\n",
      "====> In quasi-gradient: Iteration: 9000 Successive error: 0.9643937365961475\n",
      "====> In quasi-gradient: Iteration: 10000 Successive error: 0.8196010526933875\n",
      "====> In quasi-gradient: Iteration: 10001 Successive error: 0.8196010526933875\n"
     ]
    }
   ],
   "source": [
    "(x_batch, y_batch) = first(dataloader)\n",
    "i = 1\n",
    "while y_batch[i] != num\n",
    "    i += 1\n",
    "end\n",
    "\n",
    "x = x_batch[:,i]\n",
    "noise_level = .1\n",
    "\n",
    "m = 300; A = randn(m, 784)/sqrt(m)\n",
    "\n",
    "y = A*x + noise_level * randn(m)\n",
    "\n",
    "stepsize = 1\n",
    "tolerance = 1e-7\n",
    "max_iter = 10000\n",
    "out_toggle = 1000\n",
    "z_rec_PLUGIn = PLUGIn_CS(decoder, y, A, max_iter, stepsize, tolerance, out_toggle)\n",
    "error = norm(x - decoder(z_rec_PLUGIn))\n",
    "println(\"reconstruction error: $error\")\n",
    "\n",
    "z_rec_GD = GD_CS(decoder, y, A, max_iter, stepsize, tolerance, out_toggle)\n",
    "\n",
    "recovered_image_PLUGIn = colorview(Gray, reshape(decoder(z_rec_PLUGIn), 28,28)' )\n",
    "recovered_image_GD = colorview(Gray, reshape(decoder(z_rec_GD), 28,28)' )\n",
    "\n",
    "true_image = colorview(Gray, reshape(x, 28,28)' );\n",
    "p1 = plot(true_image, framestyle = :none, bg =:black, title = \"original image\")\n",
    "p2 = plot(recovered_image_PLUGIn, framestyle = :none, bg =:black, title = \"recovered image PLUGIn,\\n m = $m\")\n",
    "p3 = plot(recovered_image_GD, framestyle = :none, bg =:black, title = \"recovered image GD,\\n m = $m\")\n",
    "plot(p1, p2, p3, layout = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.7.2",
   "language": "julia",
   "name": "julia-1.7"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
