{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "using BSON: @save\n",
    "using CSV\n",
    "using DataFrames: DataFrame\n",
    "using Flux\n",
    "using Flux: logitbinarycrossentropy, binarycrossentropy\n",
    "using Flux.Data: DataLoader\n",
    "using ImageFiltering\n",
    "using MLDatasets: FashionMNIST\n",
    "using ProgressMeter: Progress, next!\n",
    "using Random\n",
    "using Zygote\n",
    "using MLDatasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We define a reshape layer to use in our decoder\n",
    "struct Reshape\n",
    "    shape\n",
    "end\n",
    "Reshape(args...) = Reshape(args)\n",
    "(r::Reshape)(x) = reshape(x, r.shape)\n",
    "Flux.@functor Reshape ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "save_model (generic function with 1 method)"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function get_train_loader(batch_size, shuffle::Bool)\n",
    "    # The FashionMNIST training set is made up of 60k 28 by 28 greyscale images\n",
    "    train_x, train_y = MNIST.traindata(Float32)\n",
    "    train_x = 1 .- reshape(train_x, (784, :))\n",
    "    # train_x = parent(padarray(train_x, Fill(0, (2,2,0,0))))\n",
    "    return DataLoader((train_x, train_y), batchsize=batch_size, shuffle=shuffle, partial=false)\n",
    "end\n",
    "\n",
    "function save_model(encoder_μ, encoder_logvar, decoder, save_dir::String, epoch::Int)\n",
    "    print(\"Saving model...\")\n",
    "    let encoder_μ = cpu(encoder_μ), encoder_logvar = cpu(encoder_logvar), decoder = cpu(decoder)\n",
    "        @save joinpath(save_dir, \"model-$epoch.bson\") encoder_μ encoder_logvar decoder\n",
    "    end\n",
    "    println(\"Done\")\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "create_vae (generic function with 1 method)"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function create_vae()\n",
    "    # Define the encoder and decoder networks\n",
    "    encoder_features = Chain(\n",
    "        Dense(784, 500, relu),\n",
    "        Dense(500, 500, relu)\n",
    "    )\n",
    "    encoder_μ = Chain(encoder_features, Dense(500, 20))\n",
    "    encoder_logvar = Chain(encoder_features, Dense(500, 20))\n",
    "\n",
    "    decoder = Chain(\n",
    "        Dense(20, 500, relu; bias = false),\n",
    "        Dense(500, 500, relu; bias = false),\n",
    "        Dense(500, 784, relu; bias = false)\n",
    "    )\n",
    "    return encoder_μ, encoder_logvar, decoder\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "train (generic function with 1 method)"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function vae_loss(encoder_μ, encoder_logvar, decoder, x, β, λ)\n",
    "    batch_size = size(x)[end]\n",
    "    @assert batch_size != 0\n",
    "\n",
    "    # Forward propagate through mean encoder and std encoders\n",
    "    μ = encoder_μ(x)\n",
    "    logvar = encoder_logvar(x)\n",
    "   # Apply reparameterisation trick to sample latent\n",
    "    z = μ + randn(Float32, size(logvar)) .* exp.(0.5f0 * logvar)\n",
    "    # Reconstruct from latent sample\n",
    "    x̂ = decoder(z)\n",
    "    # Negative reconstruction loss Ε_q[logp_x_z]\n",
    "    logp_x_z = -sum(logitbinarycrossentropy.(x̂, x)) / batch_size\n",
    "    # KL(qᵩ(z|x)||p(z)) where p(z)=N(0,1) and qᵩ(z|x) models the encoder i.e. reverse KL\n",
    "    # The @. macro makes sure that all operates are elementwise\n",
    "    kl_q_p = 0.5f0 * sum(@. (exp(logvar) + μ^2 - logvar - 1f0)) / batch_size\n",
    "    # Weight decay regularisation term\n",
    "    reg = λ * sum(x->sum(x.^2), Flux.params(encoder_μ, encoder_logvar, decoder))\n",
    "    # We want to maximise the evidence lower bound (ELBO)\n",
    "    elbo = logp_x_z - β .* kl_q_p\n",
    "    # So we minimise the sum of the negative ELBO and a weight penalty\n",
    "\n",
    "    return -elbo  + reg #+ 10*Flux.mse(x,x̂)\n",
    "end\n",
    "\n",
    "function train(encoder_μ, encoder_logvar, decoder, dataloader, num_epochs, λ, β, optimiser, save_dir)\n",
    "    # The training loop for the model\n",
    "    trainable_params = Flux.params(encoder_μ, encoder_logvar, decoder)\n",
    "\n",
    "    for epoch_num = 1:num_epochs\n",
    "        acc_loss = 0.0\n",
    "        progress_tracker = Progress(length(dataloader), 1, \"Training epoch $epoch_num: \")\n",
    "        for (x_batch, y_batch) in dataloader\n",
    "            # pullback function returns the result (loss) and a pullback operator (back)\n",
    "            loss, back = pullback(trainable_params) do\n",
    "                vae_loss(encoder_μ, encoder_logvar, decoder, x_batch, β, λ)\n",
    "            end\n",
    "            # Feed the pullback 1 to obtain the gradients and update then model parameters\n",
    "            gradients = back(1f0)\n",
    "            Flux.Optimise.update!(optimiser, trainable_params, gradients)\n",
    "            if isnan(loss)\n",
    "                break\n",
    "            end\n",
    "            acc_loss += loss\n",
    "            next!(progress_tracker; showvalues=[(:loss, loss)])\n",
    "        end\n",
    "        @assert length(dataloader) > 0\n",
    "        avg_loss = acc_loss / length(dataloader)\n",
    "        metrics = DataFrame(epoch=epoch_num, negative_elbo=avg_loss)\n",
    "        println(metrics)\n",
    "        CSV.write(joinpath(save_dir, \"metrics_temp.csv\"), metrics, header=(epoch_num==1), append=true)\n",
    "        save_model(encoder_μ, encoder_logvar, decoder, save_dir, epoch_num)\n",
    "    end\n",
    "    println(\"Training complete!\")\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "shuffle_data = true\n",
    "η = 0.001\n",
    "β = 1f0\n",
    "λ = 0.1f0\n",
    "num_epochs = 50\n",
    "save_dir = \"result\"\n",
    "# Define the model and create our data loader\n",
    "dataloader = get_train_loader(batch_size, shuffle_data);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_μ, encoder_logvar, decoder = create_vae();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Warning: ProgressMeter by default refresh meters with additional information in IJulia via `IJulia.clear_output`, which clears all outputs in the cell. \n",
      "│  - To prevent this behaviour, do `ProgressMeter.ijulia_behavior(:append)`. \n",
      "│  - To disable this warning message, do `ProgressMeter.ijulia_behavior(:clear)`.\n",
      "└ @ ProgressMeter /project/def-mpf/bjoshi/.julia/packages/ProgressMeter/Vf8un/src/ProgressMeter.jl:620\n",
      "\u001b[32mTraining epoch 50: 100%|████████████████████████████████| Time: 0:00:51\u001b[39m\n",
      "\u001b[34m  loss:  198.38498\u001b[39m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1×2 DataFrame\u001b[0m\n",
      "\u001b[1m Row \u001b[0m│\u001b[1m epoch \u001b[0m\u001b[1m negative_elbo \u001b[0m\n",
      "\u001b[1m     \u001b[0m│\u001b[90m Int64 \u001b[0m\u001b[90m Float64       \u001b[0m\n",
      "─────┼──────────────────────\n",
      "   1 │    50        187.816\n",
      "Saving model...Done\n",
      "Training complete!\n"
     ]
    }
   ],
   "source": [
    "save_dir = \"result\"\n",
    "train(encoder_μ, encoder_logvar, decoder, dataloader, num_epochs, λ, β, ADAM(η), save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Params([Float32[0.016638 0.018067371 … 0.06447321 -0.047807626; -0.053389147 -0.023183756 … -0.05648157 -0.004431855; … ; -0.01593916 -0.04394043 … -0.0509044 0.06462002; 0.05872917 0.021804819 … -0.039364353 0.059915442], Float32[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0  …  0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], Float32[-0.022843396 0.07027014 … -0.060730554 0.05914259; 0.015099515 -0.024151806 … -0.03959331 -0.06911374; … ; -0.072811484 0.030341307 … 0.037106264 -0.06256047; -0.05135092 -0.05383442 … -0.012835554 0.05560567], Float32[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0  …  0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], Float32[0.047215533 -0.07750164 … -0.07374277 0.059659265; 0.008436187 -0.07192362 … -0.011571025 0.07295769; … ; 0.06996079 -0.08291023 … 0.014697283 -0.04023047; 0.04383107 0.010922252 … -0.092576586 -0.06085716], Float32[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], Float32[0.09471508 -0.08965279 … 0.012791366 0.085051365; 0.09227601 0.07599704 … 0.096807346 -0.089696236; … ; -0.041667785 0.029034702 … 0.048231643 -0.07419158; 0.08597897 0.057463247 … -0.031907637 0.10286387], Float32[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], Float32[0.057895306 0.026636148 … 0.10400659 0.06014545; -0.07592413 0.024407964 … 0.022248764 -0.056355156; … ; -0.041808076 0.06935989 … 0.021224648 0.102585524; 0.0010984626 -0.096799426 … 0.004828508 -0.060063265], Float32[0.06820975 -0.03784689 … -0.06438088 -0.0018553792; -0.020202968 0.03841565 … -0.050361205 0.0075204307; … ; -0.06761302 0.05772728 … 0.054803465 -0.047568362; 0.03176526 0.02103103 … -0.008806354 -0.011299298], Float32[0.050193124 -0.06594454 … -0.028519195 -0.02394043; 0.0115791205 -0.019580921 … -0.027915763 -0.062691584; … ; 0.009255056 -0.06407655 … -0.018022437 0.01824655; 0.057712913 0.064427584 … 0.00787167 -0.02722719]])"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Flux.params(encoder_μ, encoder_logvar, decoder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAHAAAABwCAAAAADji6uXAAAABGdBTUEAALGPC/xhBQAAAAFzUkdCAK7OHOkAAAAgY0hSTQAAeiYAAICEAAD6AAAAgOgAAHUwAADqYAAAOpgAABdwnLpRPAAAAitJREFUaAW9wc1rFgQAB+An/I0xbeASBo4+6AuS5iVEy24dugfRpU7dO9el/6dDdO5UQlRiqNTQjObaDi2HGxmDxsJpBw++797tfdHi9zy5ryvKoizKoizKoizKoizKoizKoizKoizKoizKoizKoizKoizK4n9wB0u4jSM4ibMOFmVRFmXxH/2Ez/EH7uEpPI+jWDQqyqIsyuIxLeECvsI1bOMo5nAHJ7FoVJRFWZTFI1jDd/gWV7CGdaMu4zm8Y1SURVmUxRjL2MJNXMQqruB3k32KjzFlWJRFWZTFPrewisv4Beu4gV/xD4Ip3Mdd490zKsqiLMpiny9wG0u4jhXsYQbPYg572MOPxvsL84ZFWZRFWQz4Gl9iC1exg2nM4FW8hBP4E+smmzcqyqIsymLAJXyPTQ+dxiLO4Bms4QK+Md67DhZlURZlMeAWNg2bx3mcwi42cBW7xlt0sCiLsiiLAdtGvYUz2MYybuI3k73tYFEWZVEWA/427AMcwQY2sYzPTPYh3nCwKIuyKIsBx7GAObyAE9jCRezgOhaw7nCv4BOHi7Ioi7IY8CZ2MYUXccwDd7GHJzGNFaxg27DX8RFedrgoi7IoiwHv4xSCORzHjgdmsI1V/IwfcAN7eBqncQ7njBdlURZlsc9rhs16aBYLOI/3sIEnMIdjmDZZlEVZlMVjmsWsRxdlURZlURZlURZlURZlURZlURZlURZlURZlURZlURZlURZl/wLeTWKoeuPGMQAAAABJRU5ErkJggg==",
      "text/plain": [
       "28×28 reinterpret(reshape, Gray{Float64}, ::Matrix{Float64}) with eltype Gray{Float64}:\n",
       " Gray{Float64}(3.75058)  Gray{Float64}(3.75058)  …  Gray{Float64}(3.75058)\n",
       " Gray{Float64}(3.75058)  Gray{Float64}(3.75058)     Gray{Float64}(3.75058)\n",
       " Gray{Float64}(3.75058)  Gray{Float64}(3.75058)     Gray{Float64}(3.75058)\n",
       " Gray{Float64}(3.75058)  Gray{Float64}(3.75058)     Gray{Float64}(3.75058)\n",
       " Gray{Float64}(3.75058)  Gray{Float64}(3.7504)      Gray{Float64}(3.74502)\n",
       " Gray{Float64}(3.75058)  Gray{Float64}(3.74975)  …  Gray{Float64}(3.69951)\n",
       " Gray{Float64}(3.75058)  Gray{Float64}(3.57097)     Gray{Float64}(3.72188)\n",
       " Gray{Float64}(3.75058)  Gray{Float64}(3.55992)     Gray{Float64}(3.75449)\n",
       " Gray{Float64}(3.75058)  Gray{Float64}(3.63645)     Gray{Float64}(3.76372)\n",
       " Gray{Float64}(3.75058)  Gray{Float64}(3.65597)     Gray{Float64}(3.75105)\n",
       " Gray{Float64}(3.75058)  Gray{Float64}(3.5906)   …  Gray{Float64}(3.70034)\n",
       " Gray{Float64}(3.75058)  Gray{Float64}(3.48779)     Gray{Float64}(3.68091)\n",
       " Gray{Float64}(3.71945)  Gray{Float64}(3.41262)     Gray{Float64}(3.6274)\n",
       " ⋮                                               ⋱  \n",
       " Gray{Float64}(3.75058)  Gray{Float64}(3.47634)     Gray{Float64}(3.69732)\n",
       " Gray{Float64}(3.75058)  Gray{Float64}(3.46105)     Gray{Float64}(3.62327)\n",
       " Gray{Float64}(3.75058)  Gray{Float64}(3.60971)     Gray{Float64}(3.58273)\n",
       " Gray{Float64}(3.75058)  Gray{Float64}(3.59564)     Gray{Float64}(3.71311)\n",
       " Gray{Float64}(3.75058)  Gray{Float64}(3.65081)  …  Gray{Float64}(3.6845)\n",
       " Gray{Float64}(3.75058)  Gray{Float64}(3.76019)     Gray{Float64}(3.68034)\n",
       " Gray{Float64}(3.75058)  Gray{Float64}(3.75546)     Gray{Float64}(3.74605)\n",
       " Gray{Float64}(3.75058)  Gray{Float64}(3.75444)     Gray{Float64}(3.75091)\n",
       " Gray{Float64}(3.75058)  Gray{Float64}(3.75058)     Gray{Float64}(3.75058)\n",
       " Gray{Float64}(3.75058)  Gray{Float64}(3.75058)  …  Gray{Float64}(3.75058)\n",
       " Gray{Float64}(3.75058)  Gray{Float64}(3.75058)     Gray{Float64}(3.75058)\n",
       " Gray{Float64}(3.75058)  Gray{Float64}(3.75058)     Gray{Float64}(3.75058)"
      ]
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "colorview(Gray,reshape(decoder(randn(20)),28,28))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "using BSON: @load\n",
    "using Flux\n",
    "using Flux: chunk\n",
    "using Flux.Data: DataLoader\n",
    "using ImageFiltering\n",
    "using Images\n",
    "using ImageIO\n",
    "using MLDatasets: FashionMNIST\n",
    "using LinearAlgebra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "visualise (generic function with 1 method)"
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function get_test_loader(batch_size, shuffle::Bool)\n",
    "    # The FashionMNIST test set is made up of 10k 28 by 28 greyscale images\n",
    "    test_x, test_y = MNIST.testdata(Float32)\n",
    "    test_x = 1 .- reshape(test_x, (28*28, :))\n",
    "    # test_x = parent(padarray(test_x, Fill(0, (2,2,0,0))))\n",
    "    return DataLoader((test_x, test_y), batchsize=batch_size, shuffle=shuffle)\n",
    "end\n",
    "\n",
    "function save_to_images(x_batch, save_dir::String, prefix::String, num_images::Int64)\n",
    "    print(size(x_batch))\n",
    "    @assert num_images <= size(x_batch)[2]\n",
    "    print(num_images)\n",
    "    for i=1:num_images\n",
    "        save(joinpath(save_dir, \"$prefix-$i.png\"), colorview(Gray, reshape(clamp.(x_batch[:,i], 0, 1), 28,28)' ) )\n",
    "    end\n",
    "    colorview(Gray, reshape(clamp.(x_batch[:,1], 0, 1), 28,28))\n",
    "end\n",
    "\n",
    "function reconstruct_images(encoder_μ, encoder_logvar, decoder, x)\n",
    "    # Forward propagate through mean encoder and std encoders\n",
    "    μ = encoder_μ(x)\n",
    "    logvar = encoder_logvar(x)\n",
    "    # Apply reparameterisation trick to sample latent\n",
    "    z = μ + randn(Float32, size(logvar)) .* exp.(0.5f0 * logvar)\n",
    "    # Reconstruct from latent sample\n",
    "    x̂ = decoder(z)\n",
    "    return x̂\n",
    "end\n",
    "\n",
    "function load_model(load_dir::String, epoch::Int)\n",
    "    print(\"Loading model...\")\n",
    "    @load joinpath(load_dir, \"model-$epoch.bson\") encoder_μ encoder_logvar decoder\n",
    "    println(\"Done\")\n",
    "    return encoder_μ, encoder_logvar, decoder\n",
    "end\n",
    "\n",
    "function visualise()\n",
    "    # Define some parameters\n",
    "    batch_size = 64\n",
    "    shuffle = true\n",
    "    num_images = 30\n",
    "    epoch_to_load = 50\n",
    "    # Load the model and test set loader\n",
    "    encoder_μ, encoder_logvar, decoder = load_model(\"result\", epoch_to_load)\n",
    "    dataloader = get_test_loader(batch_size, shuffle)\n",
    "    # Reconstruct and save some images\n",
    "    for (x_batch, y_batch) in dataloader\n",
    "        save_to_images(x_batch, \"result\", \"test-image\", num_images)\n",
    "        x̂_batch = reconstruct_images(encoder_μ, encoder_logvar, decoder, x_batch)\n",
    "        save_to_images(x̂_batch, \"result\", \"reconstruction\", num_images)\n",
    "        break\n",
    "    end\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model...Done\n",
      "(784, 64)30(784, 64)30"
     ]
    }
   ],
   "source": [
    "visualise()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAHAAAABwCAAAAADji6uXAAAABGdBTUEAALGPC/xhBQAAAAFzUkdCAK7OHOkAAAAgY0hSTQAAeiYAAICEAAD6AAAAgOgAAHUwAADqYAAAOpgAABdwnLpRPAAAAjtJREFUaAW9wT1rnQUABtCT8Ag2ijQRhw4K2oIhCg4qFUTFD3BzUFDBRRzqYBVXRbH/wUlw0KUIdcgijmJNHcQSKLWUWBHSKq1DSqYOtsThDiHk3vvegjznZEdXlEVZlEVZlEVZlEVZlEVZlEVZlEVZlMVt+hIbOIznsOz2RFmURVnMYB3v44zxjuAXLBoWZVEWZTHgB7yNTZNdwof42rAoi7IoiwHr2DTsPC5i2XRRFmVRFgMexLM4beQznDDyDd7DFrZwGcumi7Ioi7IY8BRWcA3Hcdyux/EiTuEh3G1YlEVZlMWAQziIZ/C8vTawhNfwBB4wLMqiLMpiBtu4gDO4C1fwK9awhhUcxD2GRVmURVkM2Mbv+BnBGi7gH1w2cg0bmMcx00VZlEVZDPgLfxu5iXPYxHW7HsFv+Bwv4IjJoizKoiwGLGLRyP24A4u4iKtGloycx0c4ZbIoi7IoiwGH8K6RV3Ea9+FNXMWfuBM/GfkWf+Cw8aIsyqIsZnAUb2Eer9tvC1/YdRKfGi/KoizKYgYLuIV54x2w1zmTRVmURVkMuIVVPIynsWC/BXtdwQ7m7BdlURZlMWAdX+FRbOENe83Z7wbmjBdlURZlMeA7nMVZbONevGTkkvHeMVmURVmUxRQ7uG7XKlZN9zE+MFmURVmUxRRzWMEB3DDdEk7iZdNFWZRFWQw4hsdwAj/iJv6160l8glfMJsqiLMpiBkfxvf9HlEVZlEVZlEVZlEVZlEVZlEVZlEVZlP0H+59ZPpn+0WkAAAAASUVORK5CYII=",
      "text/plain": [
       "28×28 Array{Gray{N0f8},2} with eltype Gray{N0f8}:\n",
       " Gray{N0f8}(1.0)  Gray{N0f8}(1.0)  …  Gray{N0f8}(1.0)  Gray{N0f8}(1.0)\n",
       " Gray{N0f8}(1.0)  Gray{N0f8}(1.0)     Gray{N0f8}(1.0)  Gray{N0f8}(1.0)\n",
       " Gray{N0f8}(1.0)  Gray{N0f8}(1.0)     Gray{N0f8}(1.0)  Gray{N0f8}(1.0)\n",
       " Gray{N0f8}(1.0)  Gray{N0f8}(1.0)     Gray{N0f8}(1.0)  Gray{N0f8}(1.0)\n",
       " Gray{N0f8}(1.0)  Gray{N0f8}(1.0)     Gray{N0f8}(1.0)  Gray{N0f8}(1.0)\n",
       " Gray{N0f8}(1.0)  Gray{N0f8}(1.0)  …  Gray{N0f8}(1.0)  Gray{N0f8}(1.0)\n",
       " Gray{N0f8}(1.0)  Gray{N0f8}(1.0)     Gray{N0f8}(1.0)  Gray{N0f8}(1.0)\n",
       " Gray{N0f8}(1.0)  Gray{N0f8}(1.0)     Gray{N0f8}(1.0)  Gray{N0f8}(1.0)\n",
       " Gray{N0f8}(1.0)  Gray{N0f8}(1.0)     Gray{N0f8}(1.0)  Gray{N0f8}(1.0)\n",
       " Gray{N0f8}(1.0)  Gray{N0f8}(1.0)     Gray{N0f8}(1.0)  Gray{N0f8}(1.0)\n",
       " Gray{N0f8}(1.0)  Gray{N0f8}(1.0)  …  Gray{N0f8}(1.0)  Gray{N0f8}(1.0)\n",
       " Gray{N0f8}(1.0)  Gray{N0f8}(1.0)     Gray{N0f8}(1.0)  Gray{N0f8}(1.0)\n",
       " Gray{N0f8}(1.0)  Gray{N0f8}(1.0)     Gray{N0f8}(1.0)  Gray{N0f8}(1.0)\n",
       " ⋮                                 ⋱                   \n",
       " Gray{N0f8}(1.0)  Gray{N0f8}(1.0)     Gray{N0f8}(1.0)  Gray{N0f8}(1.0)\n",
       " Gray{N0f8}(1.0)  Gray{N0f8}(1.0)     Gray{N0f8}(1.0)  Gray{N0f8}(1.0)\n",
       " Gray{N0f8}(1.0)  Gray{N0f8}(1.0)     Gray{N0f8}(1.0)  Gray{N0f8}(1.0)\n",
       " Gray{N0f8}(1.0)  Gray{N0f8}(1.0)     Gray{N0f8}(1.0)  Gray{N0f8}(1.0)\n",
       " Gray{N0f8}(1.0)  Gray{N0f8}(1.0)  …  Gray{N0f8}(1.0)  Gray{N0f8}(1.0)\n",
       " Gray{N0f8}(1.0)  Gray{N0f8}(1.0)     Gray{N0f8}(1.0)  Gray{N0f8}(1.0)\n",
       " Gray{N0f8}(1.0)  Gray{N0f8}(1.0)     Gray{N0f8}(1.0)  Gray{N0f8}(1.0)\n",
       " Gray{N0f8}(1.0)  Gray{N0f8}(1.0)     Gray{N0f8}(1.0)  Gray{N0f8}(1.0)\n",
       " Gray{N0f8}(1.0)  Gray{N0f8}(1.0)     Gray{N0f8}(1.0)  Gray{N0f8}(1.0)\n",
       " Gray{N0f8}(1.0)  Gray{N0f8}(1.0)  …  Gray{N0f8}(1.0)  Gray{N0f8}(1.0)\n",
       " Gray{N0f8}(1.0)  Gray{N0f8}(1.0)     Gray{N0f8}(1.0)  Gray{N0f8}(1.0)\n",
       " Gray{N0f8}(1.0)  Gray{N0f8}(1.0)     Gray{N0f8}(1.0)  Gray{N0f8}(1.0)"
      ]
     },
     "execution_count": 275,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load(\"result/reconstruction-20.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAHAAAABwCAAAAADji6uXAAAABGdBTUEAALGPC/xhBQAAAAFzUkdCAK7OHOkAAAAgY0hSTQAAeiYAAICEAAD6AAAAgOgAAHUwAADqYAAAOpgAABdwnLpRPAAAAnpJREFUaAW9wU+oHwIAB/DPa1/rLcMiM8lT5uDEQdJb3k3RDg6UpcTFWimtyGL+LsrFScmBWtGjHbZ64hnNyZ/aQV5yIBzWSq+l589rzVPzHH6H18t+v/2ew/fzyaquKIuyKIuyKIuyKIuyKIuyKIuyKIuyKIsNOok5nMFR3IgvMYlj2IUdhouyKIuy2IDv8BgWsIpN+B0rmMT7+B4HDRdlURZlMaZ57MWigauwH89hGfvwB5aNFmVRFmUxwgp+wzOYxXlsxuN4FlcYmMPb2IHXjRZlURZlMcKn2IdFTOAGvISHrTmBQwaO4GajRVmURVkM8Q324C+sYic+w5Q1y3gUk9iOO11clEVZlMUQH2EFE9iJjzFlza94B6dxKY4ZT5RFWZTFENusuQxf4yYDp3A3fjTwFu4yniiLsiiLIa63ZgEPYQ5TOIqfMYFduNf4oizKoiyGmMGLOGTgHxyx3jbMYYvxRVmURVkMcSVewFY86b9WcQ4HMINHjCfKoizK4iKewO24D0vWW8FhzOIYXsYtRouyKIuyGMMMrsaSgRms4gsDf+NDnMYbmDZclEVZlMUYTuInAw/isIEzeA9f4QMs4F1MGy7KoizKYgxzOG/gVlxi4Do8hXOYxreYxdOYcmFRFmVRFmO4DZM4h1OYx25rtmArVrGMBUy5sCiLsiiLMdyP5/ED3sSf2IXLsYAT+AUT2ITNhouyKIuyGNNr2ItFzGIed+C49R7APYaLsiiLshjTbhzAK1jCEo5b71rsMVqURVmUxQbsx1l8gs8xie14FZOYxjVGi7Ioi7LYoIM46P+LsiiLsiiLsiiLsiiLsiiLsiiLsiiLsn8BKphvfNwCGF8AAAAASUVORK5CYII=",
      "text/plain": [
       "28×28 Array{Gray{N0f8},2} with eltype Gray{N0f8}:\n",
       " Gray{N0f8}(1.0)  Gray{N0f8}(1.0)  …  Gray{N0f8}(1.0)  Gray{N0f8}(1.0)\n",
       " Gray{N0f8}(1.0)  Gray{N0f8}(1.0)     Gray{N0f8}(1.0)  Gray{N0f8}(1.0)\n",
       " Gray{N0f8}(1.0)  Gray{N0f8}(1.0)     Gray{N0f8}(1.0)  Gray{N0f8}(1.0)\n",
       " Gray{N0f8}(1.0)  Gray{N0f8}(1.0)     Gray{N0f8}(1.0)  Gray{N0f8}(1.0)\n",
       " Gray{N0f8}(1.0)  Gray{N0f8}(1.0)     Gray{N0f8}(1.0)  Gray{N0f8}(1.0)\n",
       " Gray{N0f8}(1.0)  Gray{N0f8}(1.0)  …  Gray{N0f8}(1.0)  Gray{N0f8}(1.0)\n",
       " Gray{N0f8}(1.0)  Gray{N0f8}(1.0)     Gray{N0f8}(1.0)  Gray{N0f8}(1.0)\n",
       " Gray{N0f8}(1.0)  Gray{N0f8}(1.0)     Gray{N0f8}(1.0)  Gray{N0f8}(1.0)\n",
       " Gray{N0f8}(1.0)  Gray{N0f8}(1.0)     Gray{N0f8}(1.0)  Gray{N0f8}(1.0)\n",
       " Gray{N0f8}(1.0)  Gray{N0f8}(1.0)     Gray{N0f8}(1.0)  Gray{N0f8}(1.0)\n",
       " Gray{N0f8}(1.0)  Gray{N0f8}(1.0)  …  Gray{N0f8}(1.0)  Gray{N0f8}(1.0)\n",
       " Gray{N0f8}(1.0)  Gray{N0f8}(1.0)     Gray{N0f8}(1.0)  Gray{N0f8}(1.0)\n",
       " Gray{N0f8}(1.0)  Gray{N0f8}(1.0)     Gray{N0f8}(1.0)  Gray{N0f8}(1.0)\n",
       " ⋮                                 ⋱                   \n",
       " Gray{N0f8}(1.0)  Gray{N0f8}(1.0)     Gray{N0f8}(1.0)  Gray{N0f8}(1.0)\n",
       " Gray{N0f8}(1.0)  Gray{N0f8}(1.0)     Gray{N0f8}(1.0)  Gray{N0f8}(1.0)\n",
       " Gray{N0f8}(1.0)  Gray{N0f8}(1.0)     Gray{N0f8}(1.0)  Gray{N0f8}(1.0)\n",
       " Gray{N0f8}(1.0)  Gray{N0f8}(1.0)     Gray{N0f8}(1.0)  Gray{N0f8}(1.0)\n",
       " Gray{N0f8}(1.0)  Gray{N0f8}(1.0)  …  Gray{N0f8}(1.0)  Gray{N0f8}(1.0)\n",
       " Gray{N0f8}(1.0)  Gray{N0f8}(1.0)     Gray{N0f8}(1.0)  Gray{N0f8}(1.0)\n",
       " Gray{N0f8}(1.0)  Gray{N0f8}(1.0)     Gray{N0f8}(1.0)  Gray{N0f8}(1.0)\n",
       " Gray{N0f8}(1.0)  Gray{N0f8}(1.0)     Gray{N0f8}(1.0)  Gray{N0f8}(1.0)\n",
       " Gray{N0f8}(1.0)  Gray{N0f8}(1.0)     Gray{N0f8}(1.0)  Gray{N0f8}(1.0)\n",
       " Gray{N0f8}(1.0)  Gray{N0f8}(1.0)  …  Gray{N0f8}(1.0)  Gray{N0f8}(1.0)\n",
       " Gray{N0f8}(1.0)  Gray{N0f8}(1.0)     Gray{N0f8}(1.0)  Gray{N0f8}(1.0)\n",
       " Gray{N0f8}(1.0)  Gray{N0f8}(1.0)     Gray{N0f8}(1.0)  Gray{N0f8}(1.0)"
      ]
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "load(\"result/test-image-20.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define some parameters\n",
    "batch_size = 64\n",
    "shuffle = true\n",
    "num_images = 30\n",
    "epoch_to_load = 10\n",
    "# Load the model and test set loader\n",
    "encoder_μ, encoder_logvar, decoder = load_model(\"result\", epoch_to_load)\n",
    "dataloader = get_test_loader(batch_size, shuffle)\n",
    "# Reconstruct and save some images\n",
    "for (x_batch, y_batch) in dataloader\n",
    "    save_to_images(x_batch, \"result\", \"test-image\", num_images)\n",
    "    x̂_batch = reconstruct_images(encoder_μ, encoder_logvar, decoder, x_batch)\n",
    "    save_to_images(x̂_batch, \"result\", \"reconstruction\", num_images)\n",
    "    break\n",
    "end"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.7.2",
   "language": "julia",
   "name": "julia-1.7"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
